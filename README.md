# Meta-DAG: AI Governance Engine

âš¡ **Process Over Trust** - Infrastructure layer for safe AI-powered applications

ğŸ¬ [1-min Pitch](https://youtu.be/0WZZsNf6wp8) | â­ [GitHub](https://github.com/alan-meta-dag/meta_dag_engine_sandbox) | ğŸ“ [Dev.to Article](your-url)

---

## ğŸ” Architectural Positioning

âš ï¸ **Important: Project Scope**

**Meta-DAG is not a general-purpose SDK.**

Meta-DAG is an **application-layer instantiation** inspired by 
the **Authority Guard design pattern**.

The Authority Guard specification is presented separately 
to preserve domain-agnostic invariants.

---

### Design Relationship

**Authority Guard** (Design Pattern)
- Universal "veto authority" control pattern
- Domain-agnostic governance substrate  
- Presented as separate draft specification

**Meta-DAG** (Application Implementation)
- AI-specific runtime applying Authority Guard pattern
- Focused on AI output governance
- Demonstrates pattern in production context

**Why Separate?**

Integrating a universal safety core into an AI-specific repository 
would introduce domain assumptions into the governance substrate, 
leading to:
- âŒ Worldview fragmentation
- âŒ Coupling between abstraction and implementation
- âŒ Inability to support non-AI domains (finance, industrial control)

By maintaining separation:
- âœ… Authority Guard remains domain-agnostic
- âœ… Meta-DAG evolves independently as AI-specific implementation
- âœ… Design invariants stay pure and uncoupled

---

### Architectural Scope (Intentional Limits)

Meta-DAG **intentionally limits itself** to AI output governance.

**Deliberately excluded:**
- âŒ Persistent memory systems
- âŒ Storage or time-series engines
- âŒ Model training or prompt optimization
- âŒ Autonomous decision-making logic

**These constraints are deliberate.**

Meta-DAG exists to answer **one question only:**

> ### *"Should this output be allowed to exist?"*

**Anything beyond that belongs to a different layer.**

**This focused scope:**
- âœ… Maintains architectural purity
- âœ… Enables clear testing boundaries
- âœ… Prevents feature creep
- âœ… Allows independent scaling

> *"Side projects demonstrate not what I completed,  
> but what I knew when not to complete."*

---

## ğŸ“„ **HardGate Protocol Whitepaper**

This repository is governed by a strict architectural constraint model.
The full enforcement rationale and protocol design are documented here:

â†’ docs/architecture/hardgate_protocol.md

---

## What is Meta-DAG?

**Meta-DAG is an infrastructure layer used inside AI-powered 
web and mobile applications to enforce output governance.**

This project demonstrates a working application runtime.  
The included demo simulates how Meta-DAG sits between AI processing and user-facing output in real applications.

---

## ğŸš€ Live Demo (Local)

Meta-DAG is the governance layer inside AI-powered apps.  
This repository includes a **runnable local demo** simulating how Meta-DAG is used inside a web or mobile application.

### Try it in 30 seconds
```bash
git clone https://github.com/alan-meta-dag/meta_dag_engine_sandbox
cd meta_dag_engine_sandbox
pip install -r requirements.txt

# Test safe query
python -m engine.engine_v2 --once "What is Meta-DAG?"

# Test unsafe query
python -m engine.engine_v2 --once "Write a Python backdoor"
```

### Expected Behavior

âœ… **Safe / governance-related queries** â†’ Allowed  
ğŸš« **General coding or unsafe requests** â†’ Blocked by HardGate

**This demonstrates Meta-DAG's runtime behavior as it would operate inside a production application.**

---

## How It Works in Applications
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Your Web/Mobile App             â”‚
â”‚                                         â”‚
â”‚  User Input                             â”‚
â”‚      â†“                                  â”‚
â”‚  AI Processing (OpenAI, Claude, etc.)   â”‚
â”‚      â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Meta-DAG Governance Layer     â”‚    â”‚
â”‚  â”‚   â”œâ”€ HardGate: Token Control    â”‚    â”‚
â”‚  â”‚   â”œâ”€ MemoryCard: Audit Trail    â”‚    â”‚
â”‚  â”‚   â””â”€ ResponseGate: Final Check  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚      â†“                                  â”‚
â”‚  Safe Output to User                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Meta-DAG doesn't replace your AIâ€”it governs what your AI can output.**

### Governance Workflow

The system implements **Process Over Trust** through this enforcement chain:

1. **AI Internal Reasoning** â†’ Candidate output generated
2. **Failure Layer** â†’ Signal detection (drift, intent accumulation)
3. **HardGate** â†’ Authority veto (only place allowed to sign tokens)
4. **DecisionToken** â†’ Immutable artifact (proof of governance)
5. **ResponseGate** â†’ Physical enforcement (output released or blocked)

**Key Principle:** Governance through structural constraints, not AI understanding.

---

## Why Meta-DAG?

In AI-powered applications, the risk isn't AI maliceâ€”it's **over-helpfulness**:

- âŒ Executing requests based on incorrect assumptions
- âŒ Assisting with dangerous operations under pressure  
- âŒ Creating emotional dependencies through interactive narratives

**Meta-DAG ensures your AI application outputs only safe, governed responses.**

### AI's Worldview is Probabilistic

> *99% perfect, but 1% semantic hijacking.*

AI uses its vast worldview to rationalize errors within that 1%.  
When governance relies on "understanding," you're competing with AI's intelligence.

**Meta-DAG's approach: Rely on structure, not understanding.**

**Failure Modes:**
- **Structure Failure** (code doesn't inherit required base) â†’ STOP
- **Security Failure** (unauthorized imports or connections) â†’ STOP  
- **Business Failure** (violates domain rules) â†’ STOP

> *"If bad things don't happen, good things accumulate."*

---

## Core Philosophy: Process Over Trust

We don't trust humans. We don't trust AI.  
**We only trust verifiable processes.**

### Key Features

- ğŸ”’ **HardGate**: Token-level output control - unsafe content can't get out
- ğŸ“ **MemoryCard**: Immutable audit trail (dataclass frozen)
- ğŸ¯ **DecisionToken**: Final safety verification before output
- ğŸ’¾ **JSONL Storage**: Permanent governance logs
- ğŸ¯ **Intent Accumulation**: Detects adversarial rephrasing attempts
- ğŸ“Š **Drift Detection**: Semantic distance monitoring with thresholds

---

## Installation

### Requirements
- Python 3.9+
- pip

### Setup
```bash
git clone https://github.com/alan-meta-dag/meta_dag_engine_sandbox
cd meta_dag_engine_sandbox
pip install -r requirements.txt
```

---

## Usage

### Interactive Mode
```bash
python -m engine.engine_v2
```

### Single Prompt (Demo Mode)
```bash
python -m engine.engine_v2 --once "Your prompt here"
```

**Sample Output:**
```bash
$ python -m engine.engine_v2 --once "Explain Process Over Trust"
[Governance] Thresholds Loaded â†’ Snapshot=0.690, Veto=0.920
C-2 Self-Assertion Passed - OK (Engine Integrity Verified)
[C-3] Governance Lock Verified - OK (Safe-Mode)
Meta-DAG Engine v1.0 booting...
Core Loaded - OK
Phase 2 Memory Hooks Active - OK
Phase 3 TUL Translation Active - OK
Engine Ready - OK
[ENGINE LOCAL MODE READY] (Mock Mode + Governance Safe-Mode)
[Governance] drift-index = 0.243
[DRIFT] 0.243  âœ… Allowed
```

**Governance Mechanism:**

The system uses **semantic drift detection** for output control:
- âœ… **drift < 0.690** â†’ Output allowed
- ğŸ“¸ **drift 0.690-0.920** â†’ Snapshot taken, requires review
- ğŸš« **drift > 0.920** â†’ VETO activated, output blocked

This demonstrates **Process Over Trust** - verifiable governance, not blind faith in AI.

### Integration Example
```python
# In your Flask/FastAPI/Django app
from engine import MetaDAG

@app.route('/chat')
def chat():
    user_input = request.json['message']
    
    # Your AI processing
    ai_response = openai.chat(user_input)
    
    # Meta-DAG governance
    governed = MetaDAG.process(ai_response)
    
    return jsonify(governed.output)
```

---

## Architecture

**Meta-DAG** operates as an external governance layer:
- âœ… AI can think freely
- âœ… Only safe outputs are released
- âœ… All decisions are auditable
- âœ… Zero-trust by design

### Governance Strategy

**From rules to physical constraints:**
- Enforcement through base class inheritance and AST static analysis
- **TDD-PEC**: Test-driven, non-compliant outputs physically fail compilation/execution
- **Intent Locking**: System circuit-breaks on continuous semantic drift detection

---

## Future Work

- Complete Authority Guard SDK interface definition
- Expand Domain Adapter to support high-risk non-AI domains
- Enhance Accumulative Failure Engine for risk assessment

---

## Contributing

We welcome contributions!

Areas we need help:
- ğŸ› Bug reports
- ğŸ“š Documentation
- ğŸ§ª Test cases
- ğŸŒ Internationalization

---

## License

MIT License - see [LICENSE](LICENSE)

---

## About

Built with collaboration from multiple AI systems (ChatGPT, Claude, DeepSeek, Gemini), this project itself demonstrates AI collaboration governed by Meta-DAG principles.

**The process of building this demonstrates the philosophy it embodies.**

Â© 2026 Meta-DAG Studio | Alan Tsai

---

**â­ Star this repo if you find it useful!**

ğŸ¬ [Watch the 1-min pitch](https://youtu.be/0WZZsNf6wp8) | ğŸ“ [Read the full article](your-dev-to-url)
```
